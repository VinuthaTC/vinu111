{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgfDYBwiUznAbwy2CMDFGs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinuthaTC/vinu111/blob/main/15_12_2022_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGj1vFGcE3a2",
        "outputId": "73824843-b3bf-4642-c85e-96db48f73376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 39 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 61.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=f2675222a842c979a4bab69949b921f346529df32b2263282f09152ff247e0b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "Vs29br3MFWXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "dA8yl9vBFdWO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"pyspark_window\").getOrCreate()"
      ],
      "metadata": {
        "id": "cmZavaylFgAj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleData = ((\"Ram\", 28, \"Sales\", 3000),\n",
        "              (\"Meena\", 33, \"Sales\", 4600),\n",
        "              (\"Robin\", 40, \"Sales\", 4100),\n",
        "              (\"Kunal\", 25, \"Finance\", 3000),\n",
        "              (\"Ram\", 28, \"Sales\", 3000),\n",
        "              (\"Srishti\", 46, \"Management\", 3300),\n",
        "              (\"Jeny\", 26, \"Finance\", 3900),\n",
        "              (\"Hitesh\", 30, \"Marketing\", 3000),\n",
        "              (\"Kailash\", 29, \"Marketing\", 2000),\n",
        "              (\"Sharad\", 39, \"Sales\", 4100)\n",
        "              )"
      ],
      "metadata": {
        "id": "31VsbxXiFlhy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Employee_Name\", \"Age\",\n",
        "           \"Department\", \"Salary\"]"
      ],
      "metadata": {
        "id": "a_OawsYAFyyB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=sampleData,\n",
        "                           schema=columns)"
      ],
      "metadata": {
        "id": "NKygKw-9F7Bm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowPartition = Window.partitionBy(\"Department\").orderBy(\"Age\")"
      ],
      "metadata": {
        "id": "A6cCaDZ4F6zm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNAGfTneGTp7",
        "outputId": "043d35b8-afa7-4c6b-9440-f8bfa21b7f15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee_Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+-------------+---+----------+------+\n",
            "|Employee_Name|Age|Department|Salary|\n",
            "+-------------+---+----------+------+\n",
            "|          Ram| 28|     Sales|  3000|\n",
            "|        Meena| 33|     Sales|  4600|\n",
            "|        Robin| 40|     Sales|  4100|\n",
            "|        Kunal| 25|   Finance|  3000|\n",
            "|          Ram| 28|     Sales|  3000|\n",
            "|      Srishti| 46|Management|  3300|\n",
            "|         Jeny| 26|   Finance|  3900|\n",
            "|       Hitesh| 30| Marketing|  3000|\n",
            "|      Kailash| 29| Marketing|  2000|\n",
            "|       Sharad| 39|     Sales|  4100|\n",
            "+-------------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import cume_dist"
      ],
      "metadata": {
        "id": "gLCL1A8sGz55"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"cume_dist\",\n",
        "              cume_dist().over(windowPartition)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jstFYqsG9he",
        "outputId": "6230b173-feac-40e0-d2fe-64e507b793af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+----------+------+---------+\n",
            "|Employee_Name|Age|Department|Salary|cume_dist|\n",
            "+-------------+---+----------+------+---------+\n",
            "|        Kunal| 25|   Finance|  3000|      0.5|\n",
            "|         Jeny| 26|   Finance|  3900|      1.0|\n",
            "|      Srishti| 46|Management|  3300|      1.0|\n",
            "|      Kailash| 29| Marketing|  2000|      0.5|\n",
            "|       Hitesh| 30| Marketing|  3000|      1.0|\n",
            "|          Ram| 28|     Sales|  3000|      0.4|\n",
            "|          Ram| 28|     Sales|  3000|      0.4|\n",
            "|        Meena| 33|     Sales|  4600|      0.6|\n",
            "|       Sharad| 39|     Sales|  4100|      0.8|\n",
            "|        Robin| 40|     Sales|  4100|      1.0|\n",
            "+-------------+---+----------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag"
      ],
      "metadata": {
        "id": "kVU1-c4GJ9-W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"Lag\", lag(\"Salary\", 2).over(windowPartition)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeun6wIoJ9wQ",
        "outputId": "35af25ac-4de0-410b-d53b-0215d2e16711"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+----------+------+----+\n",
            "|Employee_Name|Age|Department|Salary| Lag|\n",
            "+-------------+---+----------+------+----+\n",
            "|        Kunal| 25|   Finance|  3000|null|\n",
            "|         Jeny| 26|   Finance|  3900|null|\n",
            "|      Srishti| 46|Management|  3300|null|\n",
            "|      Kailash| 29| Marketing|  2000|null|\n",
            "|       Hitesh| 30| Marketing|  3000|null|\n",
            "|          Ram| 28|     Sales|  3000|null|\n",
            "|          Ram| 28|     Sales|  3000|null|\n",
            "|        Meena| 33|     Sales|  4600|3000|\n",
            "|       Sharad| 39|     Sales|  4100|3000|\n",
            "|        Robin| 40|     Sales|  4100|4600|\n",
            "+-------------+---+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead"
      ],
      "metadata": {
        "id": "itG-EGSzKPQR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"Lead\", lead(\"salary\", 2).over(windowPartition)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QROFSW_ikGr8",
        "outputId": "e87aced7-c6c6-4d7b-df08-e0df46428b98"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+----------+------+----+\n",
            "|Employee_Name|Age|Department|Salary|Lead|\n",
            "+-------------+---+----------+------+----+\n",
            "|        Kunal| 25|   Finance|  3000|null|\n",
            "|         Jeny| 26|   Finance|  3900|null|\n",
            "|      Srishti| 46|Management|  3300|null|\n",
            "|      Kailash| 29| Marketing|  2000|null|\n",
            "|       Hitesh| 30| Marketing|  3000|null|\n",
            "|          Ram| 28|     Sales|  3000|4600|\n",
            "|          Ram| 28|     Sales|  3000|4100|\n",
            "|        Meena| 33|     Sales|  4600|4100|\n",
            "|       Sharad| 39|     Sales|  4100|null|\n",
            "|        Robin| 40|     Sales|  4100|null|\n",
            "+-------------+---+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "import pyspark"
      ],
      "metadata": {
        "id": "5_cLUFgrkSMM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "aFh9GB2gkrg-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"pyspark_window\").getOrCreate()"
      ],
      "metadata": {
        "id": "2ZTuRH8xkHLY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleData = ((101, \"Ram\", \"Biology\", 80),\n",
        "              (103, \"Meena\", \"Social Science\", 78),\n",
        "              (104, \"Robin\", \"Sanskrit\", 58),\n",
        "              (102, \"Kunal\", \"Phisycs\", 89),\n",
        "              (101, \"Ram\", \"Biology\", 80),\n",
        "              (106, \"Srishti\", \"Maths\", 70),\n",
        "              (108, \"Jeny\", \"Physics\", 75),\n",
        "              (107, \"Hitesh\", \"Maths\", 88),\n",
        "              (109, \"Kailash\", \"Maths\", 90),\n",
        "              (105, \"Sharad\", \"Social Science\", 84)\n",
        "              )"
      ],
      "metadata": {
        "id": "K6mQJM9lKPCe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Roll_No\", \"Student_Name\", \"Subject\", \"Marks\"]"
      ],
      "metadata": {
        "id": "lA78dpKSk_fg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.createDataFrame(data=sampleData,\n",
        "                            schema=columns)"
      ],
      "metadata": {
        "id": "I5U6YAaBlDXQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowPartition = Window.partitionBy(\"Subject\").orderBy(\"Marks\")"
      ],
      "metadata": {
        "id": "ZNvhKwwclG2J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema()\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpONzR1llGl2",
        "outputId": "496adaff-b15f-4d5c-9f13-5cc2882d4520"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Roll_No: long (nullable = true)\n",
            " |-- Student_Name: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Marks: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJcGUsPKlnPK",
        "outputId": "e7f71990-1c91-4f8e-e608-95326c71b56b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+\n",
            "|Roll_No|Student_Name|       Subject|Marks|\n",
            "+-------+------------+--------------+-----+\n",
            "|    101|         Ram|       Biology|   80|\n",
            "|    103|       Meena|Social Science|   78|\n",
            "|    104|       Robin|      Sanskrit|   58|\n",
            "|    102|       Kunal|       Phisycs|   89|\n",
            "|    101|         Ram|       Biology|   80|\n",
            "|    106|     Srishti|         Maths|   70|\n",
            "|    108|        Jeny|       Physics|   75|\n",
            "|    107|      Hitesh|         Maths|   88|\n",
            "|    109|     Kailash|         Maths|   90|\n",
            "|    105|      Sharad|Social Science|   84|\n",
            "+-------+------------+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "df2.withColumn(\"row_number\",\n",
        "               row_number().over(windowPartition)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB1eT9lc1sbX",
        "outputId": "b9a81ffc-5fb5-413c-9941-a67dcc5f793c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+----------+\n",
            "|Roll_No|Student_Name|       Subject|Marks|row_number|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "|    101|         Ram|       Biology|   80|         1|\n",
            "|    101|         Ram|       Biology|   80|         2|\n",
            "|    106|     Srishti|         Maths|   70|         1|\n",
            "|    107|      Hitesh|         Maths|   88|         2|\n",
            "|    109|     Kailash|         Maths|   90|         3|\n",
            "|    102|       Kunal|       Phisycs|   89|         1|\n",
            "|    108|        Jeny|       Physics|   75|         1|\n",
            "|    104|       Robin|      Sanskrit|   58|         1|\n",
            "|    103|       Meena|Social Science|   78|         1|\n",
            "|    105|      Sharad|Social Science|   84|         2|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank\n",
        " \n",
        "# applying the rank() function\n",
        "df2.withColumn(\"rank\", rank().over(windowPartition)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGKP15Vcm3qo",
        "outputId": "5c8c5743-d85e-4e5d-b30d-507cc7cd7eaf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+----+\n",
            "|Roll_No|Student_Name|       Subject|Marks|rank|\n",
            "+-------+------------+--------------+-----+----+\n",
            "|    101|         Ram|       Biology|   80|   1|\n",
            "|    101|         Ram|       Biology|   80|   1|\n",
            "|    106|     Srishti|         Maths|   70|   1|\n",
            "|    107|      Hitesh|         Maths|   88|   2|\n",
            "|    109|     Kailash|         Maths|   90|   3|\n",
            "|    102|       Kunal|       Phisycs|   89|   1|\n",
            "|    108|        Jeny|       Physics|   75|   1|\n",
            "|    104|       Robin|      Sanskrit|   58|   1|\n",
            "|    103|       Meena|Social Science|   78|   1|\n",
            "|    105|      Sharad|Social Science|   84|   2|\n",
            "+-------+------------+--------------+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import percent_rank\n",
        " \n",
        "# applying the percent_rank() function\n",
        "df2.withColumn(\"percent_rank\",\n",
        "               percent_rank().over(windowPartition)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CwEd9k4neDz",
        "outputId": "77dd1e84-8b35-404f-bba3-ccaae36611ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+------------+\n",
            "|Roll_No|Student_Name|       Subject|Marks|percent_rank|\n",
            "+-------+------------+--------------+-----+------------+\n",
            "|    101|         Ram|       Biology|   80|         0.0|\n",
            "|    101|         Ram|       Biology|   80|         0.0|\n",
            "|    106|     Srishti|         Maths|   70|         0.0|\n",
            "|    107|      Hitesh|         Maths|   88|         0.5|\n",
            "|    109|     Kailash|         Maths|   90|         1.0|\n",
            "|    102|       Kunal|       Phisycs|   89|         0.0|\n",
            "|    108|        Jeny|       Physics|   75|         0.0|\n",
            "|    104|       Robin|      Sanskrit|   58|         0.0|\n",
            "|    103|       Meena|Social Science|   78|         0.0|\n",
            "|    105|      Sharad|Social Science|   84|         1.0|\n",
            "+-------+------------+--------------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        " \n",
        "# applying the dense_rank() function\n",
        "df2.withColumn(\"dense_rank\",\n",
        "               dense_rank().over(windowPartition)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrBwueMUn6V6",
        "outputId": "5b4fa14e-75a1-492a-aee5-53dfe965828a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+----------+\n",
            "|Roll_No|Student_Name|       Subject|Marks|dense_rank|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "|    101|         Ram|       Biology|   80|         1|\n",
            "|    101|         Ram|       Biology|   80|         1|\n",
            "|    106|     Srishti|         Maths|   70|         1|\n",
            "|    107|      Hitesh|         Maths|   88|         2|\n",
            "|    109|     Kailash|         Maths|   90|         3|\n",
            "|    102|       Kunal|       Phisycs|   89|         1|\n",
            "|    108|        Jeny|       Physics|   75|         1|\n",
            "|    104|       Robin|      Sanskrit|   58|         1|\n",
            "|    103|       Meena|Social Science|   78|         1|\n",
            "|    105|      Sharad|Social Science|   84|         2|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"pyspark_window\").getOrCreate()"
      ],
      "metadata": {
        "id": "4jpqx-zpm3hH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleData = ((\"Ram\", \"Sales\", 3000),\n",
        "              (\"Meena\", \"Sales\", 4600),\n",
        "              (\"Robin\", \"Sales\", 4100),\n",
        "              (\"Kunal\", \"Finance\", 3000),\n",
        "              (\"Ram\", \"Sales\", 3000),\n",
        "              (\"Srishti\", \"Management\", 3300),\n",
        "              (\"Jeny\", \"Finance\", 3900),\n",
        "              (\"Hitesh\", \"Marketing\", 3000),\n",
        "              (\"Kailash\", \"Marketing\", 2000),\n",
        "              (\"Sharad\", \"Sales\", 4100)\n",
        "              )"
      ],
      "metadata": {
        "id": "NIc4UJK2onRr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Employee_Name\", \"Department\", \"Salary\"]"
      ],
      "metadata": {
        "id": "jKrw_Kxxom7k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.createDataFrame(data=sampleData,\n",
        "                            schema=columns)\n",
        " \n",
        "# print schema\n",
        "df3.printSchema()\n",
        " \n",
        "# show df\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG8YRRSgo2h1",
        "outputId": "e5ef3882-4d25-4b59-c520-06beb23b7753"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee_Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|Employee_Name|Department|Salary|\n",
            "+-------------+----------+------+\n",
            "|          Ram|     Sales|  3000|\n",
            "|        Meena|     Sales|  4600|\n",
            "|        Robin|     Sales|  4100|\n",
            "|        Kunal|   Finance|  3000|\n",
            "|          Ram|     Sales|  3000|\n",
            "|      Srishti|Management|  3300|\n",
            "|         Jeny|   Finance|  3900|\n",
            "|       Hitesh| Marketing|  3000|\n",
            "|      Kailash| Marketing|  2000|\n",
            "|       Sharad|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number"
      ],
      "metadata": {
        "id": "PFv3uZcFo5vV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowPartitionAgg  = Window.partitionBy(\"Department\")"
      ],
      "metadata": {
        "id": "Z3ExECJxo5kT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.withColumn(\"Avg\",\n",
        "               avg(col(\"salary\")).over(windowPartitionAgg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEIKdTm3pHYI",
        "outputId": "bca2925b-94a0-4382-ca3e-44506f811c28"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Employee_Name: string, Department: string, Salary: bigint, Avg: double]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.withColumn(\"Avg\",\n",
        "               avg(col(\"salary\")).over(windowPartitionAgg)).withColumn(\"Sum\",\n",
        "              sum(col(\"salary\")).over(windowPartitionAgg)).withColumn(\"Min\",\n",
        "              min(col(\"salary\")).over(windowPartitionAgg)).withColumn(\"Max\",\n",
        "              max(col(\"salary\")).over(windowPartitionAgg)).show()"
      ],
      "metadata": {
        "id": "t2Tyq26LpHMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc598a45-29d2-4e64-8f67-2dc07d665e23"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------+-----+----+----+\n",
            "|Employee_Name|Department|Salary|   Avg|  Sum| Min| Max|\n",
            "+-------------+----------+------+------+-----+----+----+\n",
            "|        Kunal|   Finance|  3000|3450.0| 6900|3000|3900|\n",
            "|         Jeny|   Finance|  3900|3450.0| 6900|3000|3900|\n",
            "|      Srishti|Management|  3300|3300.0| 3300|3300|3300|\n",
            "|       Hitesh| Marketing|  3000|2500.0| 5000|2000|3000|\n",
            "|      Kailash| Marketing|  2000|2500.0| 5000|2000|3000|\n",
            "|          Ram|     Sales|  3000|3760.0|18800|3000|4600|\n",
            "|        Meena|     Sales|  4600|3760.0|18800|3000|4600|\n",
            "|        Robin|     Sales|  4100|3760.0|18800|3000|4600|\n",
            "|          Ram|     Sales|  3000|3760.0|18800|3000|4600|\n",
            "|       Sharad|     Sales|  4100|3760.0|18800|3000|4600|\n",
            "+-------------+----------+------+------+-----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "q8XHTcxO_Ykr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"sparkdf\").getOrCreate()"
      ],
      "metadata": {
        "id": "o1u2qBxGA61l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('Jaya', '20', ['SQL','Data Science']),\n",
        "        ('Milan', '21', ['ML','AI']),\n",
        "        ('Rohit', '19', ['Programming', 'DSA']),\n",
        "        ('Maria', '20', ['DBMS', 'Networking']),\n",
        "        ('Jay', '22', ['Data Analytics','ML'])]"
      ],
      "metadata": {
        "id": "MuHdzFemA7LG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Name', 'Age', 'Courses_enrolled']"
      ],
      "metadata": {
        "id": "gTtrKdzJBAD3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data, columns)\n",
        " \n",
        "df.printSchema()\n",
        " \n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5L9UwJGBBGS",
        "outputId": "1ecc99f2-e9d1-460c-d206-2ac21c611f3f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Courses_enrolled: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-----+---+--------------------+\n",
            "| Name|Age|    Courses_enrolled|\n",
            "+-----+---+--------------------+\n",
            "| Jaya| 20| [SQL, Data Science]|\n",
            "|Milan| 21|            [ML, AI]|\n",
            "|Rohit| 19|  [Programming, DSA]|\n",
            "|Maria| 20|  [DBMS, Networking]|\n",
            "|  Jay| 22|[Data Analytics, ML]|\n",
            "+-----+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(df.Name,explode(df.Courses_enrolled))"
      ],
      "metadata": {
        "id": "pRORvxiXA7mR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.printSchema()\n",
        " \n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpAy39QO_YXx",
        "outputId": "1efb39cd-551a-4fbb-f3ac-8cd947d74ee2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+--------------+\n",
            "| Name|           col|\n",
            "+-----+--------------+\n",
            "| Jaya|           SQL|\n",
            "| Jaya|  Data Science|\n",
            "|Milan|            ML|\n",
            "|Milan|            AI|\n",
            "|Rohit|   Programming|\n",
            "|Rohit|           DSA|\n",
            "|Maria|          DBMS|\n",
            "|Maria|    Networking|\n",
            "|  Jay|Data Analytics|\n",
            "|  Jay|            ML|\n",
            "+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('Jaya', '20', ['SQL', 'Data Science']),\n",
        "        ('Milan', '21', ['ML', 'AI']),\n",
        "        ('Rohit', '19', None),\n",
        "        ('Maria', '20', ['DBMS', 'Networking']),\n",
        "        ('Jay', '22', None)]\n",
        " \n",
        "# column names for dataframe\n",
        "columns = ['Name', 'Age', 'Courses_enrolled']\n",
        " \n",
        "# creating dataframe with createDataFrame()\n",
        "df = spark.createDataFrame(data, columns)\n",
        " \n",
        "# printing dataframe schema\n",
        "df.printSchema()\n",
        " \n",
        "# show dataframe\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AJf-2NY_Xrz",
        "outputId": "6e2cb1a6-a929-450a-b951-deb7d9ed5e8f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Courses_enrolled: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-----+---+-------------------+\n",
            "| Name|Age|   Courses_enrolled|\n",
            "+-----+---+-------------------+\n",
            "| Jaya| 20|[SQL, Data Science]|\n",
            "|Milan| 21|           [ML, AI]|\n",
            "|Rohit| 19|               null|\n",
            "|Maria| 20| [DBMS, Networking]|\n",
            "|  Jay| 22|               null|\n",
            "+-----+---+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df.select(df.Name, explode_outer(df.Courses_enrolled))\n",
        " \n",
        "# printing the schema of the df4\n",
        "df4.printSchema()\n",
        " \n",
        "# show df2\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAnuKaYzCexP",
        "outputId": "c2757141-4aaa-4a70-e324-2698884561df"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+------------+\n",
            "| Name|         col|\n",
            "+-----+------------+\n",
            "| Jaya|         SQL|\n",
            "| Jaya|Data Science|\n",
            "|Milan|          ML|\n",
            "|Milan|          AI|\n",
            "|Rohit|        null|\n",
            "|Maria|        DBMS|\n",
            "|Maria|  Networking|\n",
            "|  Jay|        null|\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(df.Name, posexplode(df.Courses_enrolled))\n",
        " \n",
        "# printing the schema of the df2\n",
        "df2.printSchema()\n",
        " \n",
        "# show df2\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_hRKcA0Ceok",
        "outputId": "9bf662d9-765a-41fe-dc54-653902a95b29"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- pos: integer (nullable = false)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+---+------------+\n",
            "| Name|pos|         col|\n",
            "+-----+---+------------+\n",
            "| Jaya|  0|         SQL|\n",
            "| Jaya|  1|Data Science|\n",
            "|Milan|  0|          ML|\n",
            "|Milan|  1|          AI|\n",
            "|Maria|  0|        DBMS|\n",
            "|Maria|  1|  Networking|\n",
            "+-----+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(df.Name, posexplode_outer(df.Courses_enrolled))\n",
        " \n",
        "# printing the schema of the df2\n",
        "df2.printSchema()\n",
        " \n",
        "# show df2\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeZ5DXjUDPfb",
        "outputId": "11b45b7e-618a-45c9-c7e4-87aa319704cc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- pos: integer (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+-----+----+------------+\n",
            "| Name| pos|         col|\n",
            "+-----+----+------------+\n",
            "| Jaya|   0|         SQL|\n",
            "| Jaya|   1|Data Science|\n",
            "|Milan|   0|          ML|\n",
            "|Milan|   1|          AI|\n",
            "|Rohit|null|        null|\n",
            "|Maria|   0|        DBMS|\n",
            "|Maria|   1|  Networking|\n",
            "|  Jay|null|        null|\n",
            "+-----+----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "  \n",
        "# importing sparksession from pyspark.sql module\n",
        "from pyspark.sql import SparkSession\n",
        "  \n",
        "# creating sparksession and giving an app name\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
        "  \n",
        "# list  of employee data\n",
        "data = [[\"1\", \"sravan\", \"company 1\"],\n",
        "        [\"2\", \"ojaswi\", \"company 1\"],\n",
        "        [\"3\", \"rohith\", \"company 2\"],\n",
        "        [\"4\", \"sridevi\", \"company 1\"],\n",
        "        [\"5\", \"bobby\", \"company 1\"]]\n",
        "  \n",
        "# specify column names\n",
        "columns = ['ID', 'NAME', 'Company']\n",
        "  \n",
        "# creating a dataframe from the lists of data\n",
        "dataframe = spark.createDataFrame(data, columns)\n",
        "  \n",
        "dataframe.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtylpZQDDnIq",
        "outputId": "e2a72648-c33a-4dbd-9c59-0bcd4017edd0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------+\n",
            "| ID|   NAME|  Company|\n",
            "+---+-------+---------+\n",
            "|  1| sravan|company 1|\n",
            "|  2| ojaswi|company 1|\n",
            "|  3| rohith|company 2|\n",
            "|  4|sridevi|company 1|\n",
            "|  5|  bobby|company 1|\n",
            "+---+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [[\"1\", \"45000\", \"IT\"],\n",
        "         [\"2\", \"145000\", \"Manager\"],\n",
        "         [\"6\", \"45000\", \"HR\"],\n",
        "         [\"5\", \"34000\", \"Sales\"]]\n",
        "  \n",
        "# specify column names\n",
        "columns = ['ID', 'salary', 'department']\n",
        "  \n",
        "# creating a dataframe from the lists of data\n",
        "dataframe1 = spark.createDataFrame(data1, columns)\n",
        "  \n",
        "dataframe1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IQPlUFYEFaf",
        "outputId": "edbbb71d-84c6-4656-ae89-40b6d95cd822"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+\n",
            "| ID|salary|department|\n",
            "+---+------+----------+\n",
            "|  1| 45000|        IT|\n",
            "|  2|145000|   Manager|\n",
            "|  6| 45000|        HR|\n",
            "|  5| 34000|     Sales|\n",
            "+---+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.join(dataframe1,\n",
        "               dataframe.ID == dataframe1.ID,\n",
        "               \"inner\").drop(dataframe.ID).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJTtf5tQEZNK",
        "outputId": "07a58314-cf0f-4d36-d4d0-6462c17e65d0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+------+----------+\n",
            "|  NAME|  Company| ID|salary|department|\n",
            "+------+---------+---+------+----------+\n",
            "|sravan|company 1|  1| 45000|        IT|\n",
            "|ojaswi|company 1|  2|145000|   Manager|\n",
            "| bobby|company 1|  5| 34000|     Sales|\n",
            "+------+---------+---+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.join(dataframe1, ['ID']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9F6pxybEcuT",
        "outputId": "29ed2b1f-fdf1-4577-8609-c848d3f4dee3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---------+------+----------+\n",
            "| ID|  NAME|  Company|salary|department|\n",
            "+---+------+---------+------+----------+\n",
            "|  1|sravan|company 1| 45000|        IT|\n",
            "|  2|ojaswi|company 1|145000|   Manager|\n",
            "|  5| bobby|company 1| 34000|     Sales|\n",
            "+---+------+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}